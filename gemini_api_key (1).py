# -*- coding: utf-8 -*-
"""gemini_api_key.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B-GCKwdxHeuHG80FlgrYVl5_oLDNFdPj
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip -q install langchain

# Commented out IPython magic to ensure Python compatibility.
# %pip -q install langchain-community

# Commented out IPython magic to ensure Python compatibility.
# %pip install pypdf

# Commented out IPython magic to ensure Python compatibility.
# %pip -q install langchain-text-splitters faiss-cpu

from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS

pdf_reader=PyPDFLoader("/content/Thermodynamics_Questions_Answers.pdf")
document=pdf_reader.load()
text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=0)
chunks = text_splitter.split_documents(document)

from langchain_community import embeddings
embeddings=HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# Commented out IPython magic to ensure Python compatibility.
# %pip install faiss-cpu

db = FAISS.from_documents(chunks, embeddings)

print("FAISS database created successfully!")

pip -q install google-generativeai

import google.generativeai as genai
from google.colab import userdata
import google.generativeai as genai

# Load API key from Colab Secrets
api_key = userdata.get("RAG")

# Verify key exists (temporary check)
print(api_key is not None)

# Configure Gemini
genai.configure(api_key=api_key)

for m in genai.list_models():
  if 'generateContent' in m.supported_generation_methods:
    print(m.name)

model = genai.GenerativeModel("gemini-2.5-pro")

response = model.generate_content("what is ai.")
print(response.text)